#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æ NIMA åˆ†æ•°å·®å¼‚æœ€å¤§çš„å›¾ç‰‡
ç”Ÿæˆå…¨å›¾ vs è£å‰ªå¯¹æ¯”å›¾
"""

import os
import sys
# Add parent dir to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import cv2
import torch
import pyiqa
import numpy as np
from PIL import Image

# å‡†å¤‡æµ‹è¯•çš„å›¾ç‰‡
test_cases = [
    # åˆ†æ•°ä¸‹é™æœ€å¤šçš„
    {"file": "_Z9W8663.NEF", "full": 6.19, "crop": 4.33, "diff": -1.86},
    {"file": "_Z9W8676.NEF", "full": 6.22, "crop": 4.67, "diff": -1.55},
    {"file": "_Z9W8659.NEF", "full": 6.12, "crop": 4.81, "diff": -1.31},
    # åˆ†æ•°ä¸Šå‡æœ€å¤šçš„
    {"file": "_Z9W8853.NEF", "full": 5.45, "crop": 5.96, "diff": +0.51},
    {"file": "_Z9W8644.NEF", "full": 4.59, "crop": 5.08, "diff": +0.49},
    {"file": "_Z9W9305.NEF", "full": 5.40, "crop": 5.74, "diff": +0.35},
]

def analyze_images():
    base_dir = "/Users/jameszhenyu/Desktop/2025-08-14"
    output_dir = "/Users/jameszhenyu/PycharmProjects/SuperPicky_SandBox/scripts/analysis_output"
    os.makedirs(output_dir, exist_ok=True)
    
    device = 'mps' if torch.backends.mps.is_available() else 'cpu'
    print(f"ğŸ–¥ï¸  è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    nima = pyiqa.create_metric('nima', device=device)
    from ai_model import load_yolo_model
    from find_bird_util import raw_to_jpeg
    yolo = load_yolo_model()
    
    print("\n" + "="*70)
    print("ğŸ“Š åˆ†æ NIMA åˆ†æ•°å·®å¼‚æœ€å¤§çš„å›¾ç‰‡")
    print("="*70)
    
    for i, case in enumerate(test_cases, 1):
        filename = case['file']
        raw_path = os.path.join(base_dir, filename)
        
        if not os.path.exists(raw_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            continue
        
        print(f"\n[{i}/{len(test_cases)}] {filename}")
        print(f"   é¢„æœŸåˆ†æ•°: å…¨å›¾ {case['full']:.2f} â†’ è£å‰ª {case['crop']:.2f} ({case['diff']:+.2f})")
        
        # è½¬æ¢ RAW
        jpg_path = raw_path.rsplit('.', 1)[0] + '.jpg'
        if not os.path.exists(jpg_path):
            raw_to_jpeg(raw_path)
        
        # è¯»å–å›¾ç‰‡
        img = cv2.imread(jpg_path)
        h, w = img.shape[:2]
        print(f"   å›¾ç‰‡å°ºå¯¸: {w}x{h}")
        
        # YOLO æ£€æµ‹
        results = yolo(jpg_path, verbose=False)
        if len(results[0].boxes) == 0:
            print("   âŒ æœªæ£€æµ‹åˆ°é¸Ÿ")
            continue
        
        boxes = results[0].boxes
        best_idx = boxes.conf.argmax().item()
        box = boxes.xyxy[best_idx].cpu().numpy().astype(int)
        x1, y1, x2, y2 = box
        
        crop_w, crop_h = x2 - x1, y2 - y1
        crop_ratio = (crop_w * crop_h) / (w * h) * 100
        print(f"   è£å‰ªåŒºåŸŸ: {crop_w}x{crop_h} (å å…¨å›¾ {crop_ratio:.1f}%)")
        
        # è®¡ç®—å®é™…åˆ†æ•°
        full_score = nima(jpg_path).item()
        
        bird_crop = img[y1:y2, x1:x2]
        crop_path = "/tmp/crop_analysis.jpg"
        cv2.imwrite(crop_path, bird_crop)
        crop_score = nima(crop_path).item()
        
        print(f"   å®é™…åˆ†æ•°: å…¨å›¾ {full_score:.2f} â†’ è£å‰ª {crop_score:.2f} ({crop_score-full_score:+.2f})")
        
        # ç”Ÿæˆå¯¹æ¯”å›¾
        # åœ¨å…¨å›¾ä¸Šç”»æ£€æµ‹æ¡†
        img_with_box = img.copy()
        cv2.rectangle(img_with_box, (x1, y1), (x2, y2), (0, 255, 0), 5)
        
        # åœ¨å…¨å›¾ä¸Šæ·»åŠ åˆ†æ•°æ ‡æ³¨
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(img_with_box, f"FULL: {full_score:.2f}", (50, 150), font, 4, (0, 255, 0), 8)
        
        # å°†è£å‰ªåŒºåŸŸæ”¾å¤§åˆ°å¯æ¯”è¾ƒçš„å°ºå¯¸
        crop_display = cv2.resize(bird_crop, (int(w*0.4), int(crop_h * (w*0.4) / crop_w)))
        
        # åˆ›å»ºä¿¡æ¯é¢æ¿
        info_text = f"Full: {full_score:.2f} | Crop: {crop_score:.2f} | Diff: {crop_score-full_score:+.2f}"
        
        # ä¿å­˜å…¨å›¾ï¼ˆå¸¦æ¡†ï¼‰
        full_output = os.path.join(output_dir, f"{i}_{filename.replace('.NEF', '')}_full.jpg")
        # ç¼©å°å…¨å›¾åˆ°åˆç†å°ºå¯¸
        scale = 1500 / max(w, h)
        img_small = cv2.resize(img_with_box, (int(w*scale), int(h*scale)))
        cv2.imwrite(full_output, img_small)
        
        # ä¿å­˜è£å‰ªå›¾
        crop_output = os.path.join(output_dir, f"{i}_{filename.replace('.NEF', '')}_crop.jpg")
        cv2.imwrite(crop_output, bird_crop)
        
        print(f"   âœ… å·²ä¿å­˜: {os.path.basename(full_output)}, {os.path.basename(crop_output)}")
        
        # æ¸…ç†ä¸´æ—¶ JPG
        if os.path.exists(jpg_path):
            os.remove(jpg_path)
    
    print(f"\nğŸ“ å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {output_dir}")
    print("\n" + "="*70)
    print("ğŸ’¡ åˆ†æç»“è®º")
    print("="*70)
    print("""
åˆ†æ•°ä¸‹é™çš„æƒ…å†µ (è£å‰ªåæ›´ä½):
  - é€šå¸¸å‘ç”Ÿåœ¨èƒŒæ™¯å¾ˆç¾çš„ç…§ç‰‡ï¼ˆè™šåŒ–å…‰æ–‘ã€æš–è‰²è°ƒå¤•é˜³ç­‰ï¼‰
  - å…¨å›¾çš„æ•´ä½“æ„å›¾å’Œæ°›å›´æå‡äº†ç¾å­¦åˆ†æ•°
  - å•ç‹¬çœ‹é¸Ÿæ—¶ï¼Œå¯èƒ½é¸Ÿæœ¬èº«å§¿æ€æˆ–æ¸…æ™°åº¦ä¸€èˆ¬

åˆ†æ•°ä¸Šå‡çš„æƒ…å†µ (è£å‰ªåæ›´é«˜):
  - é€šå¸¸å‘ç”Ÿåœ¨èƒŒæ™¯æ‚ä¹±æˆ–ä¸ç¾è§‚çš„ç…§ç‰‡
  - é¸Ÿæœ¬èº«å§¿æ€ä¼˜ç¾ã€çœ¼ç¥æ¸…æ™°
  - è£å‰ªåèšç„¦äºä¸»ä½“ï¼Œæ’é™¤äº†èƒŒæ™¯å¹²æ‰°
""")


if __name__ == "__main__":
    analyze_images()
