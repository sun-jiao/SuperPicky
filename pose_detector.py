#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PoseDetector - é¸Ÿç±»å§¿æ€æ£€æµ‹å™¨
å°è£… YOLOv11-pose æ¨¡å‹çš„åŠ è½½å’Œæ¨ç†

æ”¯æŒ:
- å•å¼ å›¾ç‰‡æ£€æµ‹
- æ‰¹é‡æ£€æµ‹
- å…³é”®ç‚¹å¯è§†åŒ–
- ç»“æœå¯¼å‡º (JSON/CSV)
"""

import os
import cv2
import numpy as np
from pathlib import Path
from typing import Optional, List, Dict, Any, Union
from dataclasses import dataclass, asdict
import json

# CUB-200-2011 æ•°æ®é›†çš„15ä¸ªå…³é”®ç‚¹å®šä¹‰
BIRD_KEYPOINT_NAMES = [
    "back",           # 0: èƒŒéƒ¨
    "beak",           # 1: å–™
    "belly",          # 2: è…¹éƒ¨
    "breast",         # 3: èƒ¸éƒ¨
    "crown",          # 4: å¤´å† 
    "forehead",       # 5: å‰é¢
    "left_eye",       # 6: å·¦çœ¼
    "left_leg",       # 7: å·¦è…¿
    "left_wing",      # 8: å·¦ç¿¼
    "nape",           # 9: é¢ˆèƒŒ
    "right_eye",      # 10: å³çœ¼
    "right_leg",      # 11: å³è…¿
    "right_wing",     # 12: å³ç¿¼
    "tail",           # 13: å°¾å·´
    "throat",         # 14: å–‰å’™
]

# å…³é”®ç‚¹è¿æ¥éª¨æ¶ (ç”¨äºå¯è§†åŒ–)
BIRD_SKELETON = [
    (4, 5),   # crown - forehead
    (5, 1),   # forehead - beak
    (4, 9),   # crown - nape
    (9, 0),   # nape - back
    (0, 13),  # back - tail
    (3, 2),   # breast - belly
    (2, 7),   # belly - left_leg
    (2, 11),  # belly - right_leg
    (0, 8),   # back - left_wing
    (0, 12),  # back - right_wing
    (6, 4),   # left_eye - crown
    (10, 4),  # right_eye - crown
    (14, 3),  # throat - breast
]

# å…³é”®ç‚¹é¢œè‰² (BGRæ ¼å¼)
KEYPOINT_COLORS = {
    "head": (255, 100, 100),    # å¤´éƒ¨ç›¸å…³ - è“è‰²
    "body": (100, 255, 100),    # èº«ä½“ç›¸å…³ - ç»¿è‰²
    "limb": (100, 100, 255),    # å››è‚¢ç›¸å…³ - çº¢è‰²
    "default": (255, 255, 0),   # é»˜è®¤ - é’è‰²
}

# å…³é”®ç‚¹åˆ†ç»„
KEYPOINT_GROUPS = {
    "head": [1, 4, 5, 6, 10, 14],        # beak, crown, forehead, eyes, throat
    "body": [0, 2, 3, 9],                # back, belly, breast, nape
    "limb": [7, 8, 11, 12, 13],          # legs, wings, tail
}


@dataclass
class Keypoint:
    """å•ä¸ªå…³é”®ç‚¹æ•°æ®"""
    name: str
    x: float
    y: float
    confidence: float
    visible: bool
    
    def to_dict(self) -> dict:
        return asdict(self)


@dataclass
class BirdDetection:
    """å•åªé¸Ÿçš„æ£€æµ‹ç»“æœ"""
    bbox: tuple          # (x1, y1, x2, y2)
    confidence: float
    keypoints: List[Keypoint]
    
    @property
    def visible_keypoints(self) -> int:
        """å¯è§å…³é”®ç‚¹æ•°é‡"""
        return sum(1 for kp in self.keypoints if kp.visible)
    
    @property
    def keypoint_quality(self) -> float:
        """å…³é”®ç‚¹æ£€æµ‹è´¨é‡ (0-1)"""
        if not self.keypoints:
            return 0.0
        avg_conf = sum(kp.confidence for kp in self.keypoints) / len(self.keypoints)
        visibility_ratio = self.visible_keypoints / len(self.keypoints)
        return (avg_conf + visibility_ratio) / 2
    
    def to_dict(self) -> dict:
        return {
            "bbox": self.bbox,
            "confidence": self.confidence,
            "keypoints": [kp.to_dict() for kp in self.keypoints],
            "visible_keypoints": self.visible_keypoints,
            "keypoint_quality": self.keypoint_quality,
        }


class PoseDetector:
    """
    é¸Ÿç±»å§¿æ€æ£€æµ‹å™¨
    
    ä½¿ç”¨ YOLOv11-pose æ¨¡å‹æ£€æµ‹é¸Ÿç±»å¹¶é¢„æµ‹å…³é”®ç‚¹
    """
    
    def __init__(
        self,
        model_path: Optional[str] = None,
        device: str = "auto",
        verbose: bool = False
    ):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„ï¼ŒNoneåˆ™è‡ªåŠ¨æŸ¥æ‰¾
            device: æ¨ç†è®¾å¤‡ ("auto", "cpu", "mps", "cuda")
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        """
        self.verbose = verbose
        self.model_path = model_path or self._find_model()
        self.device = self._select_device(device)
        self.model = None
        
        self._load_model()
    
    def _find_model(self) -> str:
        """æŸ¥æ‰¾å¯ç”¨æ¨¡å‹"""
        search_paths = [
            "./models/yolo11s-pose-bird.pt",
            "./models/best.pt",
            "./yolo11s-pose.pt",
            "yolo11s-pose.pt",  # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
        ]
        
        for path in search_paths:
            if os.path.exists(path):
                return path
        
        # å¦‚æœæ‰¾ä¸åˆ°è‡ªå®šä¹‰æ¨¡å‹ï¼Œè¿”å›é¢„è®­ç»ƒæ¨¡å‹åç§°
        # Ultralytics ä¼šè‡ªåŠ¨ä¸‹è½½
        return "yolo11s-pose.pt"
    
    def _select_device(self, device: str) -> str:
        """é€‰æ‹©æ¨ç†è®¾å¤‡"""
        if device != "auto":
            return device
        
        try:
            import torch
            if torch.backends.mps.is_available():
                return "mps"
            elif torch.cuda.is_available():
                return "cuda"
        except ImportError:
            pass
        
        return "cpu"
    
    def _load_model(self):
        """åŠ è½½YOLOæ¨¡å‹"""
        try:
            from ultralytics import YOLO
            
            if self.verbose:
                print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {self.model_path}")
                print(f"   è®¾å¤‡: {self.device}")
            
            self.model = YOLO(self.model_path)
            
            if self.verbose:
                print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
                
        except Exception as e:
            raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def detect(
        self,
        image_path: str,
        conf: float = 0.25,
        iou: float = 0.45,
    ) -> Dict[str, Any]:
        """
        æ£€æµ‹å›¾ç‰‡ä¸­çš„é¸Ÿç±»å§¿æ€
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            conf: ç½®ä¿¡åº¦é˜ˆå€¼
            iou: NMS IOUé˜ˆå€¼
            
        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        if not os.path.exists(image_path):
            return {"error": f"å›¾ç‰‡ä¸å­˜åœ¨: {image_path}", "detections": []}
        
        try:
            # è¿è¡Œæ¨ç†
            results = self.model(
                image_path,
                conf=conf,
                iou=iou,
                device=self.device,
                verbose=False
            )
            
            # è§£æç»“æœ
            detections = self._parse_results(results[0])
            
            return {
                "image": image_path,
                "detections": [det.to_dict() for det in detections],
                "count": len(detections),
            }
            
        except Exception as e:
            return {"error": str(e), "detections": []}
    
    def _parse_results(self, result) -> List[BirdDetection]:
        """è§£æ YOLO æ¨ç†ç»“æœ"""
        detections = []
        
        if result.boxes is None or len(result.boxes) == 0:
            return detections
        
        boxes = result.boxes.xyxy.cpu().numpy()
        confs = result.boxes.conf.cpu().numpy()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ keypoints
        if result.keypoints is None:
            # æ²¡æœ‰å…³é”®ç‚¹æ•°æ®ï¼Œåªè¿”å›è¾¹ç•Œæ¡†
            for i, (box, conf) in enumerate(zip(boxes, confs)):
                det = BirdDetection(
                    bbox=tuple(box.tolist()),
                    confidence=float(conf),
                    keypoints=[]
                )
                detections.append(det)
            return detections
        
        # è§£æå…³é”®ç‚¹
        keypoints_data = result.keypoints.data.cpu().numpy()
        
        for i, (box, conf, kps) in enumerate(zip(boxes, confs, keypoints_data)):
            keypoints = []
            
            for j, kp in enumerate(kps):
                x, y = kp[0], kp[1]
                kp_conf = kp[2] if len(kp) > 2 else 0.0
                
                # åˆ¤æ–­å…³é”®ç‚¹åç§°
                kp_name = BIRD_KEYPOINT_NAMES[j] if j < len(BIRD_KEYPOINT_NAMES) else f"kp_{j}"
                
                keypoints.append(Keypoint(
                    name=kp_name,
                    x=float(x),
                    y=float(y),
                    confidence=float(kp_conf),
                    visible=kp_conf > 0.5
                ))
            
            det = BirdDetection(
                bbox=tuple(box.tolist()),
                confidence=float(conf),
                keypoints=keypoints
            )
            detections.append(det)
        
        return detections
    
    def detect_batch(
        self,
        image_paths: List[str],
        conf: float = 0.25,
        show_progress: bool = True
    ) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æ£€æµ‹å¤šå¼ å›¾ç‰‡
        
        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            conf: ç½®ä¿¡åº¦é˜ˆå€¼
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        total = len(image_paths)
        
        for i, path in enumerate(image_paths, 1):
            if show_progress:
                print(f"[{i}/{total}] {Path(path).name}", end=" ... ")
            
            result = self.detect(path, conf=conf)
            results.append(result)
            
            if show_progress:
                count = result.get("count", 0)
                print(f"æ£€æµ‹åˆ° {count} åªé¸Ÿ")
        
        return results
    
    def save_visualization(
        self,
        image_path: str,
        results: Dict[str, Any],
        output_dir: str,
        show_labels: bool = True,
        show_skeleton: bool = True,
    ) -> str:
        """
        ä¿å­˜å¯è§†åŒ–ç»“æœå›¾ç‰‡
        
        Args:
            image_path: åŸå›¾è·¯å¾„
            results: æ£€æµ‹ç»“æœ
            output_dir: è¾“å‡ºç›®å½•
            show_labels: æ˜¯å¦æ˜¾ç¤ºå…³é”®ç‚¹æ ‡ç­¾
            show_skeleton: æ˜¯å¦æ˜¾ç¤ºéª¨æ¶è¿æ¥
            
        Returns:
            è¾“å‡ºå›¾ç‰‡è·¯å¾„
        """
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        
        for det in results.get("detections", []):
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            bbox = det["bbox"]
            x1, y1, x2, y2 = map(int, bbox)
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # ç»˜åˆ¶ç½®ä¿¡åº¦
            conf_text = f"{det['confidence']:.2f}"
            cv2.putText(img, conf_text, (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            keypoints = det.get("keypoints", [])
            if not keypoints:
                continue
            
            # ä¸ºç»˜åˆ¶éª¨æ¶å‡†å¤‡åæ ‡
            kp_coords = {}
            
            # ç»˜åˆ¶å…³é”®ç‚¹
            for kp in keypoints:
                if not kp.get("visible", False):
                    continue
                
                x, y = int(kp["x"]), int(kp["y"])
                name = kp["name"]
                
                # å­˜å‚¨åæ ‡ç”¨äºéª¨æ¶ç»˜åˆ¶
                idx = BIRD_KEYPOINT_NAMES.index(name) if name in BIRD_KEYPOINT_NAMES else -1
                if idx >= 0:
                    kp_coords[idx] = (x, y)
                
                # é€‰æ‹©é¢œè‰²
                color = KEYPOINT_COLORS["default"]
                for group, indices in KEYPOINT_GROUPS.items():
                    if idx in indices:
                        color = KEYPOINT_COLORS[group]
                        break
                
                # ç»˜åˆ¶ç‚¹
                cv2.circle(img, (x, y), 5, color, -1)
                cv2.circle(img, (x, y), 7, (255, 255, 255), 1)
                
                # ç»˜åˆ¶æ ‡ç­¾
                if show_labels:
                    cv2.putText(img, name, (x + 8, y + 3),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
            
            # ç»˜åˆ¶éª¨æ¶
            if show_skeleton:
                for start_idx, end_idx in BIRD_SKELETON:
                    if start_idx in kp_coords and end_idx in kp_coords:
                        pt1 = kp_coords[start_idx]
                        pt2 = kp_coords[end_idx]
                        cv2.line(img, pt1, pt2, (200, 200, 200), 2)
        
        # ä¿å­˜ç»“æœ
        os.makedirs(output_dir, exist_ok=True)
        output_name = f"viz_{Path(image_path).stem}.jpg"
        output_path = os.path.join(output_dir, output_name)
        cv2.imwrite(output_path, img)
        
        return output_path
    
    def export_results(
        self,
        results: List[Dict[str, Any]],
        output_path: str,
        format: str = "json"
    ):
        """
        å¯¼å‡ºæ£€æµ‹ç»“æœ
        
        Args:
            results: æ£€æµ‹ç»“æœåˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            format: è¾“å‡ºæ ¼å¼ ("json" æˆ– "csv")
        """
        if format == "json":
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
        
        elif format == "csv":
            import csv
            with open(output_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                # è¡¨å¤´
                headers = ["image", "detection_id", "confidence", 
                          "bbox_x1", "bbox_y1", "bbox_x2", "bbox_y2",
                          "visible_keypoints", "keypoint_quality"]
                writer.writerow(headers)
                
                # æ•°æ®è¡Œ
                for result in results:
                    image = result.get("image", "")
                    for i, det in enumerate(result.get("detections", [])):
                        bbox = det.get("bbox", (0, 0, 0, 0))
                        row = [
                            image, i, det.get("confidence", 0),
                            bbox[0], bbox[1], bbox[2], bbox[3],
                            det.get("visible_keypoints", 0),
                            det.get("keypoint_quality", 0)
                        ]
                        writer.writerow(row)
        
        if self.verbose:
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {output_path}")


# ä¾¿æ·å‡½æ•°
def quick_detect(image_path: str, conf: float = 0.25) -> Dict[str, Any]:
    """å¿«é€Ÿæ£€æµ‹å•å¼ å›¾ç‰‡"""
    detector = PoseDetector(verbose=False)
    return detector.detect(image_path, conf=conf)


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    import sys
    
    if len(sys.argv) > 1:
        image_path = sys.argv[1]
        detector = PoseDetector(verbose=True)
        results = detector.detect(image_path)
        print(json.dumps(results, indent=2, ensure_ascii=False))
    else:
        print("Usage: python pose_detector.py <image_path>")
